optimizer : {
  type: AdamW,
  kwargs: {
  lr : 0.0001,
  weight_decay : 0.0005
}}

scheduler: {
  type: LambdaLR,
  kwargs: {
  decay_step: 21,
  lr_decay: 0.9,
  lowest_decay: 0.02  # min lr = lowest_decay * lr
}}

bnmscheduler: {
  type: Lambda,
  kwargs: {
  decay_step: 21,
  bn_decay: 0.5,
  bn_momentum: 0.9,
  lowest_decay: 0.01
}}

dataset : {
  train : { _base_: cfgs/dataset_configs/Projected_ShapeNet-34_noise_text.yaml,
            others: {subset: 'train',bs:20}},
  val : { _base_: cfgs/dataset_configs/Projected_ShapeNet-34_noise_text.yaml,
            others: {subset: 'test'}},
  # Optional: Uncomment to evaluate on unseen categories during training
  val_unseen : { _base_: cfgs/dataset_configs/Projected_ShapeNet-Unseen21_noise_text.yaml,
            others: {subset: 'test'}},
  test : { _base_: cfgs/dataset_configs/Projected_ShapeNet-34_noise_text.yaml,
            others: {subset: 'test'}}}

# Optional: Load pretrained weights from non-text AdaPoinTr checkpoint
# This allows transfer learning from a pretrained AdaPoinTr model
# pretrained_adapointr_path: /path/to/pretrained/adapointr/ckpt-best.pth
pretrained_adapointr_path: /home/soroushm/data/AdaPoinTr_ps34.pth

model : {
    NAME: AdaPoinTr,
    # Text conditioning configuration
    use_text_conditioning: true,
    text_encoder_name: 'ViT-bigG-14',  # OpenCLIP model for ULIP2 compatibility (1280-dim)
    # ULIP alignment loss configuration
    use_ulip_loss: true,
    ulip_loss_weight: 0.05,
    ulip_temperature: 0.07,
    ulip_config_path: null,  # Use default PointBERT config
    ulip_checkpoint_path: /home/soroushm/data/ULIP-2-PointBERT-10k-xyzrgb-pc-vit_g-objaverse_shapenet-pretrained.pt,  # Optional: path to pretrained ULIP weights
    # Original model configuration
    num_query: 512,
    num_points: 8192,
    center_num: [256, 128],
    global_feature_dim: 1024,
    encoder_type: graph,
    decoder_type: fc,
    encoder_config: {
      embed_dim: 384,
      depth: 6,
      num_heads: 6,
      k: 8,
      n_group: 2,
      mlp_ratio: 2.,
      block_style_list: ['attn-graph', 'attn', 'attn', 'attn', 'attn', 'attn'],
      combine_style: 'concat',
    },
    decoder_config: {
      embed_dim: 384,
      depth: 8,
      num_heads: 6,
      k: 8,
      n_group: 2,
      mlp_ratio: 2.,
      self_attn_block_style_list: ['attn-graph', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn'],
      self_attn_combine_style: 'concat',
      cross_attn_block_style_list: ['attn-graph', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn', 'attn'],
      cross_attn_combine_style: 'concat',
    }
}

# total_bs : 48
step_per_update : 1
max_epoch : 600

# Gradient accumulation for simulating larger batch sizes
# Effective batch size = per_gpu_batch_size * gradient_accumulation_steps * num_gpus
# Example: bs=8, gradient_accumulation_steps=6 -> effective_bs=48
gradient_accumulation_steps: 10  # Set to >1 to enable gradient accumulation

consider_metric: CDL1
